# -*- coding: utf-8 -*-
"""
Created on Tue Mar 30 15:06:29 2021

@author: u
"""

import os
import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
os.chdir('D:\Pandas')
data_income=pd.read_csv('income(1).csv')
data=data_income.copy()
print(data.info())
data.isnull().sum()
summary_num= data.describe()
print(summary_num)
summary_cate=data.describe(include="O")
print(summary_cate)
data.columns
data['JobType'].value_counts()
print(np.unique(data['JobType']))
print(np.unique(data['EdType']))
print(np.unique(data['maritalstatus']))
print(np.unique(data['occupation']))
print(np.unique(data['relationship']))
print(np.unique(data['race']))
print(np.unique(data['gender']))
print(np.unique(data['nativecountry']))
data=pd.read_csv('income(1).csv',na_values=[' ?'])
data.isnull().sum()
missing=data[data.isnull().any(axis=1)]
data2=data.dropna(axis=0)
correlation=data.corr()
gender= pd.crosstab(index=data2['gender'],columns='count',normalize=True)
gender_salstat= pd.crosstab(index=data2['gender'],columns=data2['SalStat'],margins=True,normalize='index')
SalStat=sns.countplot(data2['SalStat'])
sns.histplot(data2['age'],bins=10,kde=True)
#most of the people in consideration are in the range of 15-45 Age Group
sns.boxplot('SalStat','age',data=data2)
#higher income people has higher median age
sns.boxplot('SalStat','hoursperweek',data=data2)
#higher income is having haigher median hours per week
sns.countplot(y='JobType',data=data2,hue='SalStat')
pd.crosstab(index=data2['JobType'],columns=data2['SalStat'],normalize='index')
#only self emp inc people have approximately equal proportions both types of income categories
sns.countplot(y=data2['EdType'],hue=data2['SalStat'])
pd.crosstab(index=data2['EdType'],columns=data2['SalStat'],normalize='index')
#people who are bachelors Doctorate and prof-school as their education type
#are most likely to earn income greater than 50,000
sns.countplot(y=data2['occupation'],hue=data2['SalStat'])
pd.crosstab(index=data2['occupation'],columns=data2['SalStat'],normalize='index')
#having occupation as prof-specaility has greater chances to earn more than 50,000
#all other jobs exceptprof-speciality and exec-managerial have higher people in the criteria of earning less than 50,000
sns.histplot(data2['capitalgain'],bins=5)
#approx more than 90% of people are having 0 capital gain
sns.histplot(data2['capitalloss'],bins=5)

#===================================================================================================
#                              LOGISTIC REGRESSION
#===================================================================================================

data2['SalStat']=data2['SalStat'].map({' less than or equal to 50,000':0,' greater than 50,000':1})
print(data2['SalStat'])
# we are creating 0 and 1 for our binomial ctaegorical variable SalStat
new_data=pd.get_dummies(data2,drop_first=True)
columns_list=list(new_data.columns)
print(columns_list)
features=list(set(columns_list)-set(['SalStat']))
print(features)
y=new_data['SalStat'].values
print(y)
x=new_data[features].values
print(x)
train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.3,random_state=0)
logistic=LogisticRegression()
logistic.fit(train_x,train_y)
logistic.coef_
logistic.intercept_
prediction=logistic.predict(test_x)
print(prediction)
from sklearn.metrics import accuracy_score
accuracy_score=accuracy_score(test_y,prediction)
print(accuracy_score)
from sklearn.metrics import confusion_matrix
confusion_matrix=confusion_matrix(test_y,prediction)
print(confusion_matrix)
